{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project 3: LangChain Function/Tool Calling Calculator\n",
        "In this Project, we will create a simple LangChain Colab Notebook that uses the Google Gemini Flash model to answer user calculation questions. This example below is provided to help you get started assumes you have access to the Gemini API and a basic Python environment. However, we are required to develop and submit our project using Google Colab."
      ],
      "metadata": {
        "id": "byQoKI-zCCmU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XnBH_9WOBiZa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e44302e-9579-4957-ab76-320f6e7e42ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/2.5 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m1.9/2.5 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install python-dotenv -q\n",
        "!pip install langchain-community -U -q\n",
        "!pip install google-generativeai -U -q # Update `google-generativeai` package\n",
        "!pip install langchain -U -q\n",
        "!pip install langchain_google_genai -U -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Import API keys  in Colab from secrets\n"
      ],
      "metadata": {
        "id": "Fk5CCFapDGY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# Step 1: Retrieve the API key from Colab's user data\n",
        "api_key = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kRyWJ9SYDOsU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2: Define the Calculator Tool\n",
        "We define a Calculator class that can evaluate arithmetic expressions. The calculate method uses Python's eval function to compute the result safely."
      ],
      "metadata": {
        "id": "OLpSQezHENVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Calculator:\n",
        "    def calculate(self, expression: str) -> str:\n",
        "        try:\n",
        "            # Use Python's eval to compute the result safely\n",
        "            result = eval(expression, {\"__builtins__\": None}, {})\n",
        "            return str(result)\n",
        "        except Exception as e:\n",
        "            return f\"Error: {e}\""
      ],
      "metadata": {
        "id": "2Bre8P2QDwFg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 3: Create the Tool Wrapper for LangChain\n",
        "We integrate the calculator with LangChain as a tool using the Tool class."
      ],
      "metadata": {
        "id": "j6elD3weEUet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "\n",
        "# Define the tool using a decorator\n",
        "@tool\n",
        "def calculator(expression: str) -> str:\n",
        "    \"\"\"\n",
        "    Perform arithmetic calculations.\n",
        "    Input: A mathematical expression as a string (e.g., \"2 + 2\").\n",
        "    Output: Result of the calculation as a string.\n",
        "    \"\"\"\n",
        "    calc = Calculator()\n",
        "    return calc.calculate(expression)"
      ],
      "metadata": {
        "id": "0tXQ6UZvERsJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 4: Set Up the Google Gemini Flash Model\n",
        "We initialize the Google Gemini Flash model with the API key and define the tools to be used by the agent."
      ],
      "metadata": {
        "id": "jsAAL72MEb5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_google_genai.chat_models import ChatGoogleGenerativeAI\n",
        "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
        "\n",
        "# Initialize the Google Gemini Flash model\n",
        "gemini_model = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",  # Specify the model name, e.g., 'gemini-1.5-flash'\n",
        "    api_key=userdata.get('GOOGLE_API_KEY'),\n",
        "    temperature=0.7\n",
        ")\n",
        "print(\"Google Gemini Flash model initialized.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EM5sfUchVBKQ",
        "outputId": "1f5ef564-6314-44c4-fcbf-a5c5985d96f5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Gemini Flash model initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.tools import tool\n",
        "\n",
        "\n",
        "# Create a list of tools\n",
        "tools = [calculator]\n",
        "\n",
        "# Initialize the agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=gemini_model,\n",
        "    agent_type=\"openai-function-calling\"\n",
        ")\n",
        "\n",
        "# Example usage\n",
        "response = agent.invoke(\"What is 12 * 15?\")\n",
        "print(response)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHLFaB2om5zq",
        "outputId": "44ea2cab-6f62-45f1-b396-8070226d85ed"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': 'What is 12 * 15?', 'output': '180'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Build the Conversational Chain\n",
        "We set up a conversational chain with memory to maintain context across multiple queries.\n"
      ],
      "metadata": {
        "id": "XsLwPjpyX0sO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "# Set up memory to maintain conversation context\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "# Build the conversational chain\n",
        "chain = ConversationChain(\n",
        "    llm=gemini_model,\n",
        "    memory=memory,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Example usage\n",
        "response = chain.invoke(\"What is 12 * 15?\")\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5ar8iY9pMSK",
        "outputId": "85916203-0169-421c-fa93-e9f78c3a5e04"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-0ebed092f483>:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory()\n",
            "<ipython-input-16-0ebed092f483>:8: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
            "  chain = ConversationChain(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: What is 12 * 15?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': 'What is 12 * 15?', 'history': '', 'response': '12 * 15 is 180.  I arrived at this answer by performing the multiplication operation.  Specifically, I could have done it in a few ways:  I could have broken it down into (10 * 15) + (2 * 15) = 150 + 30 = 180. Or I could have used the standard long multiplication algorithm.  My internal processes allow me to perform these calculations very quickly.\\n'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 6: Test the Calculator Tool\n",
        "We test the calculator tool by processing a series of queries and printing the responses."
      ],
      "metadata": {
        "id": "59bQM3QXqF-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# User query\n",
        "query = \"What is 15 divided by 3?\"\n",
        "\n",
        "# Get response from the system\n",
        "response = chain.invoke(query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Esn3TYDqpyeU",
        "outputId": "fdaca138-c40e-4e42-9abe-7a52273100c1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: What is 12 * 15?\n",
            "AI: 12 * 15 is 180.  I arrived at this answer by performing the multiplication operation.  Specifically, I could have done it in a few ways:  I could have broken it down into (10 * 15) + (2 * 15) = 150 + 30 = 180. Or I could have used the standard long multiplication algorithm.  My internal processes allow me to perform these calculations very quickly.\n",
            "\n",
            "Human: What is 15 divided by 3?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': 'What is 15 divided by 3?', 'history': 'Human: What is 12 * 15?\\nAI: 12 * 15 is 180.  I arrived at this answer by performing the multiplication operation.  Specifically, I could have done it in a few ways:  I could have broken it down into (10 * 15) + (2 * 15) = 150 + 30 = 180. Or I could have used the standard long multiplication algorithm.  My internal processes allow me to perform these calculations very quickly.\\n', 'response': '15 divided by 3 is 5.  This is because 3 goes into 15 exactly five times (3 * 5 = 15).  I can perform this division using several algorithms, including long division, but in this simple case, the answer is readily apparent from my knowledge base of multiplication facts.\\n'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "queries = [\n",
        "    \"What is 25 multiplied by 4?\",\n",
        "    \"Now divide the result by 5.\",\n",
        "    \"Add 10 to that.\"\n",
        "]\n",
        "\n",
        "for q in queries:\n",
        "    print(\"Query:\", q)\n",
        "    print(\"Response:\", chain.invoke(q))\n",
        "    print(\"-\" * 40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTQ2klForHjM",
        "outputId": "76072fe6-be55-4266-dbfc-706b4db40787"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What is 25 multiplied by 4?\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: What is 12 * 15?\n",
            "AI: 12 * 15 is 180.  I arrived at this answer by performing the multiplication operation.  Specifically, I could have done it in a few ways:  I could have broken it down into (10 * 15) + (2 * 15) = 150 + 30 = 180. Or I could have used the standard long multiplication algorithm.  My internal processes allow me to perform these calculations very quickly.\n",
            "\n",
            "Human: What is 15 divided by 3?\n",
            "AI: 15 divided by 3 is 5.  This is because 3 goes into 15 exactly five times (3 * 5 = 15).  I can perform this division using several algorithms, including long division, but in this simple case, the answer is readily apparent from my knowledge base of multiplication facts.\n",
            "\n",
            "Human: What is 25 multiplied by 4?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Response: {'input': 'What is 25 multiplied by 4?', 'history': 'Human: What is 12 * 15?\\nAI: 12 * 15 is 180.  I arrived at this answer by performing the multiplication operation.  Specifically, I could have done it in a few ways:  I could have broken it down into (10 * 15) + (2 * 15) = 150 + 30 = 180. Or I could have used the standard long multiplication algorithm.  My internal processes allow me to perform these calculations very quickly.\\n\\nHuman: What is 15 divided by 3?\\nAI: 15 divided by 3 is 5.  This is because 3 goes into 15 exactly five times (3 * 5 = 15).  I can perform this division using several algorithms, including long division, but in this simple case, the answer is readily apparent from my knowledge base of multiplication facts.\\n', 'response': '25 multiplied by 4 is 100.  I can calculate this in a few ways.  One is to think of it as (25 * 2) * 2 = 50 * 2 = 100.  Another is to think of it as four quarters making a dollar, scaled up by 100.  Or, I could use the standard multiplication algorithm. My internal representation allows for efficient calculation of such arithmetic problems.\\n'}\n",
            "----------------------------------------\n",
            "Query: Now divide the result by 5.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: What is 12 * 15?\n",
            "AI: 12 * 15 is 180.  I arrived at this answer by performing the multiplication operation.  Specifically, I could have done it in a few ways:  I could have broken it down into (10 * 15) + (2 * 15) = 150 + 30 = 180. Or I could have used the standard long multiplication algorithm.  My internal processes allow me to perform these calculations very quickly.\n",
            "\n",
            "Human: What is 15 divided by 3?\n",
            "AI: 15 divided by 3 is 5.  This is because 3 goes into 15 exactly five times (3 * 5 = 15).  I can perform this division using several algorithms, including long division, but in this simple case, the answer is readily apparent from my knowledge base of multiplication facts.\n",
            "\n",
            "Human: What is 25 multiplied by 4?\n",
            "AI: 25 multiplied by 4 is 100.  I can calculate this in a few ways.  One is to think of it as (25 * 2) * 2 = 50 * 2 = 100.  Another is to think of it as four quarters making a dollar, scaled up by 100.  Or, I could use the standard multiplication algorithm. My internal representation allows for efficient calculation of such arithmetic problems.\n",
            "\n",
            "Human: Now divide the result by 5.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Response: {'input': 'Now divide the result by 5.', 'history': 'Human: What is 12 * 15?\\nAI: 12 * 15 is 180.  I arrived at this answer by performing the multiplication operation.  Specifically, I could have done it in a few ways:  I could have broken it down into (10 * 15) + (2 * 15) = 150 + 30 = 180. Or I could have used the standard long multiplication algorithm.  My internal processes allow me to perform these calculations very quickly.\\n\\nHuman: What is 15 divided by 3?\\nAI: 15 divided by 3 is 5.  This is because 3 goes into 15 exactly five times (3 * 5 = 15).  I can perform this division using several algorithms, including long division, but in this simple case, the answer is readily apparent from my knowledge base of multiplication facts.\\n\\nHuman: What is 25 multiplied by 4?\\nAI: 25 multiplied by 4 is 100.  I can calculate this in a few ways.  One is to think of it as (25 * 2) * 2 = 50 * 2 = 100.  Another is to think of it as four quarters making a dollar, scaled up by 100.  Or, I could use the standard multiplication algorithm. My internal representation allows for efficient calculation of such arithmetic problems.\\n', 'response': \"100 divided by 5 is 20. This is because 5 goes into 100 twenty times (5 * 20 = 100).  The calculation is straightforward and readily apparent from my knowledge base of multiplication and division facts.  I could also use long division, but it's unnecessary for this simple problem.\\n\"}\n",
            "----------------------------------------\n",
            "Query: Add 10 to that.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: What is 12 * 15?\n",
            "AI: 12 * 15 is 180.  I arrived at this answer by performing the multiplication operation.  Specifically, I could have done it in a few ways:  I could have broken it down into (10 * 15) + (2 * 15) = 150 + 30 = 180. Or I could have used the standard long multiplication algorithm.  My internal processes allow me to perform these calculations very quickly.\n",
            "\n",
            "Human: What is 15 divided by 3?\n",
            "AI: 15 divided by 3 is 5.  This is because 3 goes into 15 exactly five times (3 * 5 = 15).  I can perform this division using several algorithms, including long division, but in this simple case, the answer is readily apparent from my knowledge base of multiplication facts.\n",
            "\n",
            "Human: What is 25 multiplied by 4?\n",
            "AI: 25 multiplied by 4 is 100.  I can calculate this in a few ways.  One is to think of it as (25 * 2) * 2 = 50 * 2 = 100.  Another is to think of it as four quarters making a dollar, scaled up by 100.  Or, I could use the standard multiplication algorithm. My internal representation allows for efficient calculation of such arithmetic problems.\n",
            "\n",
            "Human: Now divide the result by 5.\n",
            "AI: 100 divided by 5 is 20. This is because 5 goes into 100 twenty times (5 * 20 = 100).  The calculation is straightforward and readily apparent from my knowledge base of multiplication and division facts.  I could also use long division, but it's unnecessary for this simple problem.\n",
            "\n",
            "Human: Add 10 to that.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Response: {'input': 'Add 10 to that.', 'history': \"Human: What is 12 * 15?\\nAI: 12 * 15 is 180.  I arrived at this answer by performing the multiplication operation.  Specifically, I could have done it in a few ways:  I could have broken it down into (10 * 15) + (2 * 15) = 150 + 30 = 180. Or I could have used the standard long multiplication algorithm.  My internal processes allow me to perform these calculations very quickly.\\n\\nHuman: What is 15 divided by 3?\\nAI: 15 divided by 3 is 5.  This is because 3 goes into 15 exactly five times (3 * 5 = 15).  I can perform this division using several algorithms, including long division, but in this simple case, the answer is readily apparent from my knowledge base of multiplication facts.\\n\\nHuman: What is 25 multiplied by 4?\\nAI: 25 multiplied by 4 is 100.  I can calculate this in a few ways.  One is to think of it as (25 * 2) * 2 = 50 * 2 = 100.  Another is to think of it as four quarters making a dollar, scaled up by 100.  Or, I could use the standard multiplication algorithm. My internal representation allows for efficient calculation of such arithmetic problems.\\n\\nHuman: Now divide the result by 5.\\nAI: 100 divided by 5 is 20. This is because 5 goes into 100 twenty times (5 * 20 = 100).  The calculation is straightforward and readily apparent from my knowledge base of multiplication and division facts.  I could also use long division, but it's unnecessary for this simple problem.\\n\", 'response': 'Adding 10 to 20 results in 30.  This is a simple addition operation. My internal processes represent numbers in a way that allows for efficient addition.  I simply incremented the value of 20 by 10.\\n'}\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------"
      ],
      "metadata": {
        "id": "OXkj29bgOlD_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9MyyYdiaBXst"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
